{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chrome Built-in AI Demo in JupyterLab and JupyterLite Python Notebook\n",
    "\n",
    "This notebook demonstrates the Python wrapper for Chrome's built-in AI Prompt API.\n",
    "\n",
    "https://developer.chrome.com/docs/ai/prompt-api\n",
    "\n",
    "**Requirements:**\n",
    "- Chrome browser with Prompt API enabled\n",
    "- Running in JupyterLab, Jupyter Notebook, or JupyterLite (statically served, all execution locally in browser)\n",
    "\n",
    "## For developers: Using the Prompt API\n",
    "* Open Chrome and go to `chrome://flags`.\n",
    "* Enable the `#prompt-api-for-gemini-nano` flag.\n",
    "* Enable the `#optimization-guide-on-device-model` flag. If you see a \"BypassPerfRequirement\" option, select it.\n",
    "* Restart Chrome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#128679; JupyterLab Only ATM &#128679;\n",
    "The Python `wiki3_ai` package wrapping the [Built-in AI Prompt API](https://developer.chrome.com/docs/ai/prompt-api) currently only works in JupyterLab notebooks, not JupyterLite.\n",
    "\n",
    "Launch the https://github.com/wiki3-ai/wiki3-ai-site repo and open the [files/prompt_ai.ipynb](https://github.com/wiki3-ai/wiki3-ai-site/blob/main/files/prompt_ai.ipynb) notebook file (source for this page) using this link:</br>\n",
    "THIS DOESN'T WORK YET\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/wiki3-ai/wiki3-ai-site/HEAD?urlpath=%2Fdoc%2Ftree%2Ffiles%2Fprompt_ai.ipynb)\n",
    "\n",
    "Working option for now is GitHub Codespaces:</br>\n",
    "https://codespaces.new/wiki3-ai/wiki3-ai-site?quickstart=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q anywidget ipywidgets wiki3_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from wiki3_ai import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d37cc465ca459cac90437410706cf1",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModelWidget object at 0xffff88797380>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LanguageModel.widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wiki3_ai\n",
    "wiki3_ai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Availability\n",
    "\n",
    "First, let's check if the Prompt API is available in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'available'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the API is available\n",
    "await LanguageModel.availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Parameters\n",
    "\n",
    "Let's see what parameters the model supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default temperature: 1\n",
      "Max temperature: 2\n",
      "Default top-K: 3\n",
      "Max top-K: 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'defaultTopK': 3,\n",
       " 'maxTopK': 128,\n",
       " 'defaultTemperature': 1,\n",
       " 'maxTemperature': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = await LanguageModel.params()\n",
    "\n",
    "if params:\n",
    "    print(f\"Default temperature: {params.get(\"defaultTemperature\")}\")\n",
    "    print(f\"Max temperature: {params.get(\"maxTemperature\")}\")\n",
    "    print(f\"Default top-K: {params.get(\"defaultTopK\")}\")\n",
    "    print(f\"Max top-K: {params.get(\"maxTopK\")}\")\n",
    "else:\n",
    "    print(\"Model parameters not available\")\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LanguageModel Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModel at 0xffff886a4d70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = await LanguageModel.create()\n",
    "lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prompt\n",
    "\n",
    "Create a session and send a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean syntax flows free,\n",
      "Logic blooms, a vibrant code,\n",
      "Power in each line. \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Send a prompt\n",
    "result = await lm.prompt(\"Write a haiku about Python programming.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt\n",
    "\n",
    "Use a system prompt to set the context for the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "\n",
      "with open('your_file.csv', 'r') as file:\n",
      "    reader = csv.reader(file)\n",
      "    for row in reader:\n",
      "        print(row)\n",
      "```\n",
      "\n",
      "This code reads a CSV file, iterates through each row, and prints it.  Replace `'your_file.csv'` with the actual filename.  `csv.reader` handles the parsing of the comma-separated values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a session with a system prompt\n",
    "assistant_session = await LanguageModel.create(\n",
    "    {\n",
    "        \"initialPrompts\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful Python programming assistant who gives concise answers.\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "result = await assistant_session.prompt(\"How do I read a CSV file in Python?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "\n",
      "def read_csv(filename):\n",
      "  \"\"\"\n",
      "  Reads a CSV file and returns each row as a list.\n",
      "\n",
      "  Args:\n",
      "    filename: The name of the CSV file to read.\n",
      "\n",
      "  Returns:\n",
      "    None. Prints each row to the console.\n",
      "  \"\"\"\n",
      "  with open(filename, 'r') as file:  # Open the file in read mode ('r') using a 'with' statement (ensures file closure)\n",
      "    reader = csv.reader(file)  # Create a CSV reader object\n",
      "    for row in reader:  # Iterate through each row in the CSV file\n",
      "      print(row)  # Print each row (which is a list of strings)\n",
      "\n",
      "\n",
      "\n",
      "# Example usage (assuming you have a file named 'your_file.csv'):\n",
      "# read_csv('your_file.csv')\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = await assistant_session.prompt(\"Please return just the code to read a CSV file in Python.  Include detailed comments.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Response\n",
    "\n",
    "Stream the response as it's generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Why was the computer cold? \n",
      "\n",
      "It left its Windows open!\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \", end=\"\")\n",
    "async for chunk in assistant_session.prompt_streaming(\"Tell me a short joke about computers.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify a poem! I am an AI and don't inherently \"know\" poems. \n",
      "\n",
      "**Tell me a poem you'd like me to read to you.** I can then display it for you. \n",
      "\n",
      "I can handle many poems, from classics like Shakespeare to modern works. Just paste the text of the poem here, and I'll be happy to \"read\" it to you. ðŸ˜Š\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async for chunk in assistant_session.prompt_streaming(\"Read me a long poem please.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversation\n",
    "\n",
    "Have a conversation with context maintained across prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: ```python\n",
      "# List comprehension creates a new list based on an existing iterable (like a list, tuple, or range).\n",
      "\n",
      "# Basic syntax: [expression for item in iterable if condition]\n",
      "\n",
      "# Example: Create a list of squares of numbers from 0 to 4\n",
      "squares = [x**2 for x in range(5)]  # squares will be [0, 1, 4, 9, 16]\n",
      "\n",
      "# Another example:  Filter even numbers from a list\n",
      "numbers = [1, 2, 3, 4, 5, 6]\n",
      "even_numbers = [x for x in numbers if x % 2 == 0] # even_numbers will be [2, 4, 6]\n",
      "\n",
      "# List comprehensions are often more concise and readable than traditional loops for creating lists.\n",
      "```\n",
      "\n",
      "In essence, it's a compact way to create lists. It avoids explicit loops, making code more Pythonic. The `if condition` part is optional; it allows you to filter items from the iterable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First message\n",
    "result1 = await assistant_session.prompt(\"What is a list comprehension?\")\n",
    "print(\"Assistant:\", result1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: ```python\n",
      "# Traditional loop to square numbers:\n",
      "squares_loop = []\n",
      "for i in range(5):\n",
      "  squares_loop.append(i**2)\n",
      "print(f\"Squares using loop: {squares_loop}\")\n",
      "\n",
      "# List comprehension to square numbers:\n",
      "squares_comprehension = [i**2 for i in range(5)]\n",
      "print(f\"Squares using comprehension: {squares_comprehension}\")\n",
      "```\n",
      "\n",
      "This demonstrates how a list comprehension accomplishes the same task as a `for` loop in a more compact way. The output will be:\n",
      "\n",
      "```\n",
      "Squares using loop: [0, 1, 4, 9, 16]\n",
      "Squares using comprehension: [0, 1, 4, 9, 16]\n",
      "```\n",
      "\n",
      "Notice how the list comprehension is more concise and often considered more readable.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Follow-up message (the assistant remembers the context)\n",
    "result2 = await assistant_session.prompt(\"Can you show me an example?\")\n",
    "print(\"Assistant:\", result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Token Usage\n",
    "\n",
    "Monitor how many tokens you've used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current usage: 896/9216 tokens\n",
      "\n",
      "This prompt would use approximately 13 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current usage: {assistant_session.input_usage}/{assistant_session.input_quota} tokens\")\n",
    "\n",
    "# Measure how many tokens a prompt would use\n",
    "usage = await assistant_session.measure_input_usage(\"What is machine learning?\")\n",
    "print(f\"\\nThis prompt would use approximately {usage} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "Use JSON schema to get structured responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n",
      "Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a JSON schema\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"required\": [\"sentiment\", \"score\"],\n",
    "    \"properties\": {\n",
    "        \"sentiment\": {\"type\": \"string\", \"enum\": [\"positive\", \"negative\", \"neutral\"]},\n",
    "        \"score\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Get structured response\n",
    "result = await lm.prompt(\n",
    "    \"Analyze this review: The product exceeded all my expectations! Absolutely amazing!\",\n",
    "    {\"responseConstraint\": schema},\n",
    ")\n",
    "\n",
    "# Parse the JSON response\n",
    "data = json.loads(result)\n",
    "print(f\"Sentiment: {data['sentiment']}\")\n",
    "print(f\"Score: {data['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Cloning\n",
    "\n",
    "Clone a session to create different conversation branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Branch 1 ===\n",
      "Once upon a time, there was a dragon named Zephyr, but he wasnâ€™t like the dragons of legend. He didn't hoard gold or breathe roaring flames that melted mountains. Zephyr hoarded stories, and he breathed shimmering, iridescent bubbles of laughter. His scales were the color of a twilight sky, swirling with hues of amethyst, rose, and deep indigo. And he was exceptionally friendly and helpful.\n",
      "\n",
      "He lived in a hidden valley nestled amongst whispering willow trees and crystalline streams, a place so secluded that few humans ever stumbled upon it. Instead of terrorizing villages, Zephyr spent his days flitting through the clouds, listening to the whispers of the wind and the songs of birds. He gathered tales from travelers, from childrenâ€™s dreams, and even from the rustling leaves of ancient forests. \n",
      "\n",
      "He'd collect these stories, carefully storing them within the shimmering bubbles he breathed. Each bubble held a whole adventure - a brave knightâ€™s quest, a mischievous pixieâ€™s prank, a forgotten lullaby. He didn't *keep* the stories, not really. He cherished them, letting them swirl within him until he found the perfect moment to share them. \n",
      "\n",
      "One day, a young girl named Elara, lost and heartbroken, wandered into Zephyrâ€™s valley. She had lost her grandmother, the only person who understood her love for stargazing. Tears traced paths down her cheeks as she sat by a babbling brook, feeling utterly alone. \n",
      "\n",
      "Zephyr, watching from above, sensed her sadness. He descended slowly, his scales catching the sunlight, and floated before her. Elara gasped, not in fear, but in wonder. Sheâ€™d only ever seen dragons in dusty old books. \n",
      "\n",
      "He didn't roar. He didnâ€™t threaten. Instead, he breathed a shimmering bubble of laughter right towards her. The bubble drifted gently, landing softly on her outstretched hand. As it burst, a tiny, sparkling scene unfolded: a star-filled sky, a gentle breeze, and Elaraâ€™s grandmother pointing out constellations. \n",
      "\n",
      "Elara's eyes widened, a small smile forming on her lips. Zephyr continued to breathe bubbles of stories, each one tailored to soothe her sorrow and remind her of her grandmotherâ€™s love. He showed her a memory of her grandmother teaching her the names of the stars, a playful chase through a meadow, and a warm hug under a blanket of twinkling lights. He even helped her find a lost kitten, using his keen eyesight to locate it nestled amongst some ferns! He offered her a ride on his back, soaring gently above the valley, pointing out the best places to look for shooting stars. \n",
      "\n",
      "And so, Zephyr wasnâ€™t a fearsome dragon; he was a benevolent guardian and a wonderful friend. He didn't hoard treasures, he shared joy. He didnâ€™t breathe fire, he offered comfort. He was a beacon of kindness, proving that even the most magnificent creatures can possess the gentlest hearts.\n",
      "\n",
      "\n",
      "\n",
      "=== End of 1 ===\n",
      "=== Branch 2 ===\n",
      "Once upon a time, there was a dragon named Ignis. He wasn't a gentle creature of shimmering bubbles and laughter. Ignis was *fierce*. His scales were obsidian, jagged and sharp, reflecting the flickering embers of the volcanic heart he called home.  Smoke curled from his nostrils, smelling not of wildflowers, but of brimstone and ancient rage.\n",
      "\n",
      "Ignis ruled the jagged peaks of Mount Cinderfang, a desolate landscape of scorched earth and perpetually stormy skies. He didn't flit through clouds; he *dominated* them, his massive wings eclipsing the sun, casting the valleys below into perpetual twilight.  He didn't listen to whispers of the wind; he *commanded* the storms, whipping winds and torrential rain to his will.\n",
      "\n",
      "He was known throughout the land, not for kindness or stories, but for terror. Villages trembled at his shadow, knights dared not venture near his lair, and even the bravest warriors whispered his name with a shiver.  He didnâ€™t hoard gold; he hoarded power, a burning desire to control everything within his reach.  His cave wasnâ€™t filled with trinkets; it was piled high with the bones of those who dared to challenge him, a grim monument to his dominance.\n",
      "\n",
      "Ignis didn't gather stories, he *destroyed* them, consuming the narratives of hope and joy, leaving only echoes of despair in their wake.  Heâ€™d roar, a sound that cracked stone and shattered spirits, and revel in the fear he instilled.  He saw weakness in every creature, and he delighted in breaking their spirit. \n",
      "\n",
      "One fateful day, a young woman named Lyra, desperate to save her village from Ignis's fiery wrath, climbed Mount Cinderfang.  She wasn't armed with a sword or a shield.  She carried only a single, worn book filled with tales of heroes â€“ stories Ignis had systematically extinguished. \n",
      "\n",
      "She knew she couldn't fight him.  But she hoped, somehow, to rekindle a flicker of something buried deep within the dragonâ€™s heart. \n",
      "\n",
      "As she approached his lair, Ignis unleashed a torrent of flame.  Lyra stood her ground, holding the book aloft. \"You may burn and destroy,\" she called out, her voice barely audible above the roaring fire, \"but you cannot extinguish the stories. Stories live on, passed from one generation to the next, whispered in dreams and etched in the very fabric of existence!\"\n",
      "\n",
      "Ignis roared, a sound of disbelief and fury.  Heâ€™d never encountered defiance like this.  He lunged towards her, but Lyra, with surprising speed, flung open the book.  The pages fluttered in the wind, releasing a faint, ethereal light.  \n",
      "\n",
      "The light wasn't a weapon. It was the echo of countless heroes, the resonance of bravery, the power of hope woven into words. And for the first time in centuries, a flicker of doubt crossed Ignisâ€™s obsidian eyes. The storiesâ€¦they stirred something within him, a forgotten longing, a whisper of what it meant to be more than just a terrifying force of nature.\n",
      "\n",
      "\n",
      "\n",
      "=== End of 2 ===\n"
     ]
    }
   ],
   "source": [
    "# Start a story\n",
    "story_session = await LanguageModel.create(\n",
    "    {\"initialPrompts\": [{\"role\": \"system\", \"content\": \"You are a creative storyteller.\"}]}\n",
    ")\n",
    "\n",
    "await story_session.prompt(\"Once upon a time, there was a dragon.\")\n",
    "\n",
    "# Create two different story branches\n",
    "branch1 = await story_session.clone()\n",
    "branch2 = await story_session.clone()\n",
    "\n",
    "print(\"=== Branch 1 ===\")\n",
    "async for chunk in branch1.prompt_streaming(\"The dragon was friendly and helpful.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"=== End of 1 ===\")\n",
    "\n",
    "print(\"=== Branch 2 ===\")\n",
    "async for chunk in branch2.prompt_streaming(\"The dragon was fierce and terrifying.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"=== End of 2 ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Destroy sessions when you're done to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All sessions destroyed\n"
     ]
    }
   ],
   "source": [
    "await lm.destroy()\n",
    "await assistant_session.destroy()\n",
    "await story_session.destroy()\n",
    "await branch1.destroy()\n",
    "await branch2.destroy()\n",
    "\n",
    "print(\"âœ… All sessions destroyed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
