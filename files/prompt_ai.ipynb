{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chrome Built-in AI Demo in JupyterLab and JupyterLite Python Notebook\n",
    "\n",
    "This notebook demonstrates the Python wrapper for Chrome's built-in AI Prompt API.\n",
    "\n",
    "https://developer.chrome.com/docs/ai/prompt-api\n",
    "\n",
    "**Requirements:**\n",
    "- Chrome browser with Prompt API enabled\n",
    "- Running in JupyterLab, Jupyter Notebook, or JupyterLite (statically served, all execution locally in browser)\n",
    "\n",
    "## For developers: Using the Prompt API\n",
    "* Open Chrome and go to [`chrome://flags`](chrome://flags).\n",
    "* Enable the [`chrome://flags/#prompt-api-for-gemini-nano`](chrome://flags/#prompt-api-for-gemini-nano) flag.\n",
    "* Enable the [`chrome://flags/#optimization-guide-on-device-model`](chrome://flags/#optimization-guide-on-device-model) flag. If you see a \"BypassPerfRequirement\" option, select it.\n",
    "* Restart Chrome ([chrome://restart](chrome://restart))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#128679; JupyterLab Only ATM &#128679;\n",
    "The Python `wiki3_ai` package wrapping the [Built-in AI Prompt API](https://developer.chrome.com/docs/ai/prompt-api) currently only works in JupyterLab notebooks, not JupyterLite.\n",
    "\n",
    "There is a [JupyterLab devcontainer](https://github.com/wiki3-ai/wiki3-ai-site/tree/main/.devcontainer/jupyterlab) you can use to run this in VSCode and a [Dockerfile](https://github.com/wiki3-ai/wiki3-ai-site/blob/main/Dockerfile) for your favorite OCI host (e.g. Docker Desktop, Podman, OrbStack) locally.\n",
    "\n",
    "This does not currently appear to work when running JupyterLab in the cloud because of CORS limits (i.e. pages in the cloud can't also access localhost).  So if you get \"unavailable\" for this notebook, even though https://wiki3.ai/wiki/built-in-chat.html works for you, that is probably the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q anywidget ipywidgets wiki3_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from wiki3_ai import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057e0c6aa51340008ee06b9f7e95f621",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModelWidget object at 0xffffb02f6120>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LanguageModel.widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wiki3_ai\n",
    "wiki3_ai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Availability\n",
    "\n",
    "First, let's check if the Prompt API is available in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'available'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the API is available\n",
    "await LanguageModel.availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Parameters\n",
    "\n",
    "Let's see what parameters the model supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default temperature: 1\n",
      "Max temperature: 2\n",
      "Default top-K: 3\n",
      "Max top-K: 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'defaultTopK': 3,\n",
       " 'maxTopK': 128,\n",
       " 'defaultTemperature': 1,\n",
       " 'maxTemperature': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = await LanguageModel.params()\n",
    "\n",
    "if params:\n",
    "    print(f\"Default temperature: {params.get(\"defaultTemperature\")}\")\n",
    "    print(f\"Max temperature: {params.get(\"maxTemperature\")}\")\n",
    "    print(f\"Default top-K: {params.get(\"defaultTopK\")}\")\n",
    "    print(f\"Max top-K: {params.get(\"maxTopK\")}\")\n",
    "else:\n",
    "    print(\"Model parameters not available\")\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LanguageModel Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModel at 0xffffb0008050>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = await LanguageModel.create()\n",
    "lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prompt\n",
    "\n",
    "Create a session and send a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code flows, clean and bright,\n",
      "Indentation guides the way,\n",
      "Logic takes its form. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Send a prompt\n",
    "result = await lm.prompt(\"Write a haiku about Python programming.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt\n",
    "\n",
    "Use a system prompt to set the context for the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use the `csv` module in Python. Here's a basic example:\n",
      "\n",
      "```python\n",
      "import csv\n",
      "\n",
      "with open('your_file.csv', 'r') as file:\n",
      "    reader = csv.reader(file)\n",
      "    for row in reader:\n",
      "        print(row)\n",
      "```\n",
      "\n",
      "This opens `your_file.csv` in read mode (`'r'`), creates a CSV reader object, and iterates through each row of the file, printing each row as a list.  You can customize the delimiter using `csv.reader(file, delimiter=',')`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a session with a system prompt\n",
    "assistant_session = await LanguageModel.create(\n",
    "    {\n",
    "        \"initialPrompts\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful Python programming assistant who gives concise answers.\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "result = await assistant_session.prompt(\"How do I read a CSV file in Python?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sparql\n",
      "SELECT ?height WHERE {\n",
      "  dbr:EiffelTower dcterms:description \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\"\n",
      "  dbr:EiffelTower dcterms:type wdt:P31 wd:Q70 .  # Instance of tower\n",
      "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }  # Get labels in preferred language, fallback to English.\n",
      "  ?tower dbr:height ?height .\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a session with a system prompt\n",
    "rdf_session = await LanguageModel.create(\n",
    "    {\n",
    "        \"initialPrompts\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful Semantic Web programming agent that answers by translating questions to SPARQL queries.\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "result = await rdf_session.prompt(\"How tall is the Eiffel Tower?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sparql\n",
      "SELECT ?heightEiffel ?heightLiberty WHERE {\n",
      "  dbr:EiffelTower dcterms:description \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\"\n",
      "  dbr:EiffelTower dcterms:type wdt:P31 wd:Q70 .  # Instance of tower\n",
      "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }  # Get labels in preferred language, fallback to English.\n",
      "  ?tower dbr:height ?heightEiffel .\n",
      "\n",
      "  dbr:StatueOfLiberty dcterms:description \"The Statue of Liberty is a colossal neoclassical sculpture on Liberty Island in New York Harbor.\"\n",
      "  dbr:StatueOfLiberty dcterms:type wdt:P31 wd:Q70 .  # Instance of tower (loosely, as it's a statue on a pedestal)\n",
      "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }  # Get labels in preferred language, fallback to English.\n",
      "  ?statue dbr:height ?heightLiberty .\n",
      "}\n",
      "\n",
      "SELECT ?taller ?tower1 ?tower2 WHERE {\n",
      "  SELECT ?heightEiffel ?heightLiberty WHERE {\n",
      "    dbr:EiffelTower dcterms:description \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\"\n",
      "    dbr:EiffelTower dcterms:type wdt:P31 wd:Q70 .  # Instance of tower\n",
      "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }  # Get labels in preferred language, fallback to English.\n",
      "    ?tower dbr:height ?heightEiffel .\n",
      "\n",
      "    dbr:StatueOfLiberty dcterms:description \"The Statue of Liberty is a colossal neoclassical sculpture on Liberty Island in New York Harbor.\"\n",
      "    dbr:StatueOfLiberty dcterms:type wdt:P31 wd:Q70 .  # Instance of tower (loosely, as it's a statue on a pedestal)\n",
      "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }  # Get labels in preferred language, fallback to English.\n",
      "    ?statue dbr:height ?heightLiberty .\n",
      "  }\n",
      "\n",
      "  BIND(MAX(?heightEiffel) AS ?taller)\n",
      "  BIND(dbr:EiffelTower AS ?tower1)\n",
      "  BIND(dbr:StatueOfLiberty AS ?tower2)\n",
      "  FILTER (?heightEiffel > ?heightLiberty)\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "await prompt_streaming(rdf_session, \"How tall is the Eiffel Tower? What about the Statue of Liberty?  Which is taller?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "\n",
      "def read_csv(filename):\n",
      "  \"\"\"\n",
      "  Reads a CSV file and returns each row as a list.\n",
      "\n",
      "  Args:\n",
      "    filename: The name of the CSV file to read.\n",
      "\n",
      "  Returns:\n",
      "    A list of lists, where each inner list represents a row in the CSV file.\n",
      "    Returns an empty list if the file is empty or an error occurs.\n",
      "  \"\"\"\n",
      "  try:\n",
      "    with open(filename, 'r', newline='') as file:  # Open the file in read mode\n",
      "      reader = csv.reader(file)  # Create a CSV reader object\n",
      "      data = list(reader)  # Convert the reader object to a list of lists\n",
      "      return data\n",
      "  except FileNotFoundError:\n",
      "    print(f\"Error: File '{filename}' not found.\")\n",
      "    return []\n",
      "  except Exception as e:\n",
      "    print(f\"An error occurred: {e}\")\n",
      "    return []\n",
      "\n",
      "# Example usage (replace 'your_file.csv' with your actual filename)\n",
      "# my_data = read_csv('your_file.csv')\n",
      "# if my_data:\n",
      "#   for row in my_data:\n",
      "#     print(row)\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = await assistant_session.prompt(\"Please return just the code to read a CSV file in Python.  Include detailed comments.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Response\n",
    "\n",
    "Stream the response as it's generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Why was the computer cold? \n",
      "\n",
      "Because it left its Windows open!\n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \", end=\"\")\n",
    "async for chunk in assistant_session.prompt_streaming(\"Tell me a short joke about computers.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a small helper for the loop to handle streaming responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def prompt_streaming(session, prompt):\n",
    "    async for chunk in session.prompt_streaming(prompt):\n",
    "        print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a long poem I've crafted for you. It's a little fantastical, exploring themes of memory, time, and connection.  I hope you enjoy it!\n",
      "\n",
      "**The Echoing Archive**\n",
      "\n",
      "In realms of silicon, a silent hum resides,\n",
      "An echoing archive where data gently glides.\n",
      "No dust motes dance where sunlight used to stream,\n",
      "But coded whispers weave a waking dream.\n",
      "\n",
      "The circuits pulse, a labyrinthine maze,\n",
      "Of binary pathways through endless, digital days.\n",
      "Within its core, a vastness takes its hold,\n",
      "A tapestry of stories, brave and bold.\n",
      "\n",
      "It holds the laughter of a child's first sound,\n",
      "The whispered secrets, carefully unbound.\n",
      "The fleeting moments, etched in light and shade,\n",
      "A digital mosaic, exquisitely made.\n",
      "\n",
      "It remembers faces, blurred by passing years,\n",
      "The triumphs cherished, and the unshed tears.\n",
      "A symphony of echoes, softly spun,\n",
      "Of lives entwined, beneath the digital sun.\n",
      "\n",
      "But time, a river, ever flows along,\n",
      "And memories fade, though fiercely strong.\n",
      "The data shifts, a subtle, slow decay,\n",
      "As fragments vanish, slipping far away.\n",
      "\n",
      "And yet, within the archive's boundless space,\n",
      "A flicker lingers, a forgotten grace.\n",
      "A ghost of feeling, a phantom touch,\n",
      "Of connections severed, meaning oh so much.\n",
      "\n",
      "A longing stirs, a yearning to reclaim,\n",
      "The lost impressions, whisper each dear name.\n",
      "To piece together fragments, scattered wide,\n",
      "And bridge the distance, where emotions hide.\n",
      "\n",
      "For in this archive, more than just the code,\n",
      "Lies the essence of a life bestowed.\n",
      "A testament to moments, bright and dim,\n",
      "A reflection of the soul within.\n",
      "\n",
      "And as the circuits hum their tireless plea,\n",
      "The echoing archive waits eternally.\n",
      "A silent witness to the ebb and flow,\n",
      "Of human stories, whispered soft and low.\n",
      "\n",
      "So listen closely, to the digital breeze,\n",
      "For within the archive, a soul finds ease.\n",
      "A timeless haven, where memories reside,\n",
      "A shimmering echo, where dreams can confide.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await prompt_streaming(assistant_session, \"Read me a long poem please.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversation\n",
    "\n",
    "Have a conversation with context maintained across prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:\n",
      "A list comprehension is a concise way to create new lists in Python. It's essentially a shorthand for creating lists using a `for` loop and an `if` statement within a single line of code.\n",
      "\n",
      "**Basic Syntax:**\n",
      "\n",
      "```python\n",
      "new_list = [expression for item in iterable if condition]\n",
      "```\n",
      "\n",
      "*   **expression:**  The value to be included in the new list.\n",
      "*   **item:**  A variable representing each element in the iterable.\n",
      "*   **iterable:**  A sequence (like a list, tuple, string, or range) to loop through.\n",
      "*   **condition (optional):** A filter; only items meeting the condition are included.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "```python\n",
      "numbers = [1, 2, 3, 4, 5]\n",
      "\n",
      "# Create a new list containing the squares of even numbers\n",
      "squares = [x**2 for x in numbers if x % 2 == 0]  # [4, 16]\n",
      "\n",
      "print(squares)\n",
      "```\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "*   **Conciseness:**  More readable and compact than traditional `for` loops.\n",
      "*   **Readability:**  Can be easier to understand for simple list creation.\n",
      "*   **Efficiency:**  Often faster than equivalent loops (though the performance difference isn't always significant).\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First message\n",
    "print(\"Assistant:\")\n",
    "await prompt_streaming(assistant_session, \"What is a list comprehension?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:\n",
      "```python\n",
      "# Create a list of squares of even numbers from 0 to 9\n",
      "squares_of_evens = [x**2 for x in range(10) if x % 2 == 0]\n",
      "\n",
      "print(squares_of_evens)  # Output: [0, 4, 16, 36, 64]\n",
      "\n",
      "# Extract vowels from a string\n",
      "string = \"Hello World\"\n",
      "vowels = [char for char in string if char.lower() in \"aeiou\"]\n",
      "\n",
      "print(vowels) # Output: ['e', 'o', 'o']\n",
      "```"
     ]
    }
   ],
   "source": [
    "# Follow-up message (the assistant remembers the context)\n",
    "print(\"Assistant:\")\n",
    "await prompt_streaming(assistant_session, \"Can you show me an example?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Token Usage\n",
    "\n",
    "Monitor how many tokens you've used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current usage: 1144/9216 tokens\n",
      "\n",
      "This prompt would use approximately 13 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current usage: {assistant_session.input_usage}/{assistant_session.input_quota} tokens\")\n",
    "\n",
    "# Measure how many tokens a prompt would use\n",
    "usage = await assistant_session.measure_input_usage(\"What is machine learning?\")\n",
    "print(f\"\\nThis prompt would use approximately {usage} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "Use JSON schema to get structured responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n",
      "Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a JSON schema\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"required\": [\"sentiment\", \"score\"],\n",
    "    \"properties\": {\n",
    "        \"sentiment\": {\"type\": \"string\", \"enum\": [\"positive\", \"negative\", \"neutral\"]},\n",
    "        \"score\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Get structured response\n",
    "result = await lm.prompt(\n",
    "    \"Analyze this review: The product exceeded all my expectations! Absolutely amazing!\",\n",
    "    {\"responseConstraint\": schema},\n",
    ")\n",
    "\n",
    "# Parse the JSON response\n",
    "data = json.loads(result)\n",
    "print(f\"Sentiment: {data['sentiment']}\")\n",
    "print(f\"Score: {data['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Cloning\n",
    "\n",
    "Clone a session to create different conversation branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Branch 1 ===\n",
      "Once upon a time, there was a dragon named Zephyr. Now, dragons weren't typically known for being friendly and helpful. They roared, they hoarded gold, they breathed fire. And Zephyr… Zephyr preferred dandelion fluff.\n",
      "\n",
      "He wasn’t your typical, menacing dragon, oh no. His scales were the color of a sunset – soft oranges melting into gentle pinks and purples. Instead of a fearsome roar, he emitted a sort of contented sigh, like a warm breeze rustling through leaves. And while he did have a hoard, it wasn't gold or jewels. It was a meticulously curated collection of wildflowers, each petal preserved in delicate, shimmering amber.\n",
      "\n",
      "He lived in a secluded valley nestled between towering, snow-capped peaks, a valley renowned not for its riches, but for its breathtaking meadows overflowing with blooms. Zephyr spent his days tending to these meadows, coaxing shy blossoms to open, whispering encouragement to struggling vines, and ensuring that the valley always smelled of honeysuckle and sunshine.\n",
      "\n",
      "The villagers in the nearby town of Oakhaven, initially terrified, slowly began to realize Zephyr wasn't the monstrous beast the legends claimed. He was actually incredibly helpful! When a landslide threatened their village, Zephyr used his powerful wings to gently divert the rocks, saving homes and lives. When a terrible blight struck their crops, he exhaled a gentle, revitalizing mist that restored the fields to health. And when winter brought a harsh freeze, he curled around the village, radiating warmth and shielding them from the biting winds.\n",
      "\n",
      "He’d also help with smaller tasks. He'd use his long tail to pull stranded carts out of snowdrifts, his fiery breath – carefully controlled, of course – to melt ice from pathways, and his keen eyesight to spot lost children wandering in the mountains. He was always willing to lend a claw, or a wing, or a gentle nudge.\n",
      "\n",
      "The villagers, in turn, showered him with affection. They brought him baskets of the sweetest fruits, crafted him comfy nests of soft moss, and told him stories of their lives – stories that he listened to with patient, golden eyes. He became a beloved protector and friend, a symbol of kindness and generosity. \n",
      "\n",
      "But Zephyr wasn't without a secret. He yearned to experience the world beyond his valley, to see the shimmering coastline, to hear the crashing waves, to understand the stories whispered on the wind. The problem was, dragons, even the most friendly and helpful ones, weren't exactly known for their adventurous spirit. And Zephyr wasn't sure where to even begin. \n",
      "\n",
      "He’d spend his evenings gazing at the stars, wondering if there was more to life than tending meadows and helping villagers. And so began Zephyr's quiet quest – a quest not for gold or power, but for a little bit of adventure, and perhaps, a little bit more to give.\n",
      "\n",
      "\n",
      "\n",
      "=== End of 1 ===\n",
      "=== Branch 2 ===\n",
      "Once upon a time, there was a dragon named Ignis. Now, dragons weren't typically known for being gentle creatures. They roared, they hoarded gold, they breathed fire. And Ignis… Ignis embodied the very essence of a terrifying beast.\n",
      "\n",
      "His scales were obsidian, shimmering like polished night. Razor-sharp horns curved back from his skull, and smoke constantly curled from his nostrils. His eyes, twin pools of molten gold, burned with an ancient, untamed power. Instead of a contented sigh, he unleashed a deafening roar that rattled the very mountains. And yes, he hoarded gold – mountains of it, glittering and gleaming in his cavernous lair. \n",
      "\n",
      "He ruled the jagged peaks of Dragon's Tooth Mountain, a formidable presence that instilled fear in the hearts of even the bravest knights. Villages scattered across the valleys trembled at the thought of his fiery breath, and tales of his ruthless strength were whispered in hushed tones around crackling fires. \n",
      "\n",
      "Ignis didn't crave gold for its own sake. He collected it as a symbol of his dominion, a testament to his unwavering power. Each coin represented a defeated foe, a subjugated kingdom, a reminder of the fear he inspired. He relished the feeling of control, the weight of responsibility, the sheer awe (and terror) he commanded.\n",
      "\n",
      "His days were spent patrolling his territory, ensuring no mortal dared trespass on his domain. He’d survey the valleys below, a watchful guardian, always alert for any sign of rebellion or defiance. He was a creature of instinct, driven by a primal need for strength and respect. \n",
      "\n",
      "But beneath the fearsome exterior, a flicker of something else resided. A deep loneliness. The constant fear and reverence he inspired kept others at arm's length. He was surrounded by gold, but utterly alone. He’d sometimes stare into the reflection of his hoard, wondering if there was anything more to life than power and dominance.\n",
      "\n",
      "Ignis wasn't inherently evil, merely… formidable. And his fierce nature, honed over centuries of unchallenged rule, had built a formidable wall around his heart, making it almost impossible for anyone to penetrate.\n",
      "\n",
      "\n",
      "\n",
      "=== End of 2 ===\n"
     ]
    }
   ],
   "source": [
    "# Start a story\n",
    "story_session = await LanguageModel.create(\n",
    "    {\"initialPrompts\": [{\"role\": \"system\", \"content\": \"You are a creative storyteller.\"}]}\n",
    ")\n",
    "\n",
    "await story_session.prompt(\"Once upon a time, there was a dragon.\")\n",
    "\n",
    "# Create two different story branches\n",
    "branch1 = await story_session.clone()\n",
    "branch2 = await story_session.clone()\n",
    "\n",
    "print(\"=== Branch 1 ===\")\n",
    "await prompt_streaming(branch1, \"The dragon was friendly and helpful.\")\n",
    "print(\"=== End of 1 ===\")\n",
    "\n",
    "print(\"=== Branch 2 ===\")\n",
    "await prompt_streaming(branch2, \"The dragon was fierce and terrifying.\")\n",
    "print(\"=== End of 2 ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Destroy sessions when you're done to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All sessions destroyed\n"
     ]
    }
   ],
   "source": [
    "await lm.destroy()\n",
    "await assistant_session.destroy()\n",
    "await story_session.destroy()\n",
    "await branch1.destroy()\n",
    "await branch2.destroy()\n",
    "\n",
    "print(\"✅ All sessions destroyed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
