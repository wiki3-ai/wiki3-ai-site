{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chrome Built-in AI Demo in JupyterLab and JupyterLite Python Notebook\n",
    "\n",
    "This notebook demonstrates the Python wrapper for Chrome's built-in AI Prompt API.\n",
    "\n",
    "https://developer.chrome.com/docs/ai/prompt-api\n",
    "\n",
    "**Requirements:**\n",
    "- Chrome browser with Prompt API enabled\n",
    "- Running in JupyterLab, Jupyter Notebook, or JupyterLite (statically served, all execution locally in browser)\n",
    "\n",
    "## For developers: Using the Prompt API\n",
    "* Open Chrome and go to `chrome://flags`.\n",
    "* Enable the `#prompt-api-for-gemini-nano` flag.\n",
    "* Enable the `#optimization-guide-on-device-model` flag. If you see a \"BypassPerfRequirement\" option, select it.\n",
    "* Restart Chrome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#128679; JupyterLab Only ATM &#128679;\n",
    "The Python `wiki3_ai` package wrapping the [Built-in AI Prompt API](https://developer.chrome.com/docs/ai/prompt-api) currently only works in JupyterLab notebooks, not JupyterLite.\n",
    "\n",
    "Launch the https://github.com/wiki3-ai/wiki3-ai-site repo and open the [files/prompt_ai.ipynb](https://github.com/wiki3-ai/wiki3-ai-site/blob/main/files/prompt_ai.ipynb) notebook file (source for this page) using this link:</br>\n",
    "THIS DOESN'T WORK YET\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/wiki3-ai/wiki3-ai-site/HEAD?urlpath=%2Fdoc%2Ftree%2Ffiles%2Fprompt_ai.ipynb)\n",
    "\n",
    "Working option for now is GitHub Codespaces.  Choose the jupyterlab devcontainer:</br>\n",
    "https://codespaces.new/wiki3-ai/wiki3-ai-site?quickstart=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q anywidget ipywidgets wiki3_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from wiki3_ai import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb5f47241ef4edea777c5b88646649e",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModelWidget object at 0xffff842e2120>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LanguageModel.widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wiki3_ai\n",
    "wiki3_ai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Availability\n",
    "\n",
    "First, let's check if the Prompt API is available in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'available'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the API is available\n",
    "await LanguageModel.availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Parameters\n",
    "\n",
    "Let's see what parameters the model supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default temperature: 1\n",
      "Max temperature: 2\n",
      "Default top-K: 3\n",
      "Max top-K: 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'defaultTopK': 3,\n",
       " 'maxTopK': 128,\n",
       " 'defaultTemperature': 1,\n",
       " 'maxTemperature': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = await LanguageModel.params()\n",
    "\n",
    "if params:\n",
    "    print(f\"Default temperature: {params.get(\"defaultTemperature\")}\")\n",
    "    print(f\"Max temperature: {params.get(\"maxTemperature\")}\")\n",
    "    print(f\"Default top-K: {params.get(\"defaultTopK\")}\")\n",
    "    print(f\"Max top-K: {params.get(\"maxTopK\")}\")\n",
    "else:\n",
    "    print(\"Model parameters not available\")\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LanguageModel Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModel at 0xffff842e3cb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = await LanguageModel.create()\n",
    "lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prompt\n",
    "\n",
    "Create a session and send a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean syntax unfolds,\n",
      "Logic flows, a gentle stream,\n",
      "Code breathes, life takes form. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Send a prompt\n",
    "result = await lm.prompt(\"Write a haiku about Python programming.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt\n",
    "\n",
    "Use a system prompt to set the context for the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "\n",
      "with open('your_file.csv', 'r') as file:\n",
      "    reader = csv.reader(file)\n",
      "    for row in reader:\n",
      "        print(row)\n",
      "```\n",
      "\n",
      "This opens the CSV file, creates a reader object, and iterates through each row, printing it to the console.  Replace `'your_file.csv'` with the actual filename.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a session with a system prompt\n",
    "assistant_session = await LanguageModel.create(\n",
    "    {\n",
    "        \"initialPrompts\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful Python programming assistant who gives concise answers.\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "result = await assistant_session.prompt(\"How do I read a CSV file in Python?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "\n",
      "# Open the CSV file in read mode ('r').  The 'with' statement ensures the file is automatically closed.\n",
      "with open('your_file.csv', 'r') as file:\n",
      "    # Create a CSV reader object. This object iterates over the rows of the CSV file.\n",
      "    reader = csv.reader(file)\n",
      "    # Iterate through each row in the CSV file. Each row is a list of strings.\n",
      "    for row in reader:\n",
      "        # Process each row here.  For example, print it.\n",
      "        print(row)\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = await assistant_session.prompt(\"Please return just the code to read a CSV file in Python.  Include detailed comments.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Response\n",
    "\n",
    "Stream the response as it's generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Why was the computer cold? \n",
      "\n",
      "It left its Windows open!\n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \", end=\"\")\n",
    "async for chunk in assistant_session.prompt_streaming(\"Tell me a short joke about computers.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a small helper for the loop to handle streaming responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def prompt_streaming(session, prompt):\n",
    "    async for chunk in session.prompt_streaming(prompt):\n",
    "        print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a longer poem. It's a bit whimsical, exploring the idea of a forgotten library and the stories held within.  I hope you enjoy it!\n",
      "\n",
      "**The Dust and Echoes of Old Books**\n",
      "\n",
      "In a town hushed by time's slow hand,\n",
      "Stands a library, a forgotten land.\n",
      "Stone walls draped in ivy's green,\n",
      "A silent keeper of what's been.\n",
      "\n",
      "Dust motes dance in shafts of light,\n",
      "Illuminating shadows, soft and white.\n",
      "Rows of shelves, a towering grace,\n",
      "Holding worlds in this quiet place.\n",
      "\n",
      "Leather-bound spines, a whispered plea,\n",
      "To unlock tales for all to see.\n",
      "Stories of heroes, brave and bold,\n",
      "Legends of ages, new and old.\n",
      "\n",
      "Each book a portal, a hidden door,\n",
      "To kingdoms lost and so much more.\n",
      "Of dragons soaring on windswept heights,\n",
      "And mermaids singing in moonlit nights.\n",
      "\n",
      "The scent of aged paper fills the air,\n",
      "A comforting aroma beyond compare.\n",
      "Of ink and parchment, a fragrant blend,\n",
      "Where imaginations effortlessly transcend.\n",
      "\n",
      "A forgotten scholar, a wistful sigh,\n",
      "Remembers the stories that drift by.\n",
      "He traces the titles with trembling hand,\n",
      "A yearning for worlds he'll never stand.\n",
      "\n",
      "The library sleeps, a peaceful dream,\n",
      "Of characters vibrant, a flowing stream.\n",
      "Of whispered secrets and fortunes untold,\n",
      "In the pages of stories, brave and bold.\n",
      "\n",
      "Though time marches onward, relentless and fast,\n",
      "The echoes of stories forever will last.\n",
      "Within these walls, a timeless embrace,\n",
      "A sanctuary of wonder, a magical space.\n",
      "\n",
      "So step inside, if you dare to roam,\n",
      "And let the old library be your home.\n",
      "For within its depths, a magic resides,\n",
      "Where the dust and the echoes forever abide.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await prompt_streaming(assistant_session, \"Read me a long poem please.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversation\n",
    "\n",
    "Have a conversation with context maintained across prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:\n",
      "A list comprehension is a concise way to create new lists in Python. It's essentially a shorthand for creating lists using a `for` loop and an `if` statement within a single line of code.\n",
      "\n",
      "**Basic Syntax:**\n",
      "\n",
      "```python\n",
      "new_list = [expression for item in iterable if condition]\n",
      "```\n",
      "\n",
      "*   **expression:**  The value to be included in the new list.\n",
      "*   **item:**  A variable representing each element in the iterable.\n",
      "*   **iterable:**  A sequence (like a list, tuple, string, or range) to loop through.\n",
      "*   **condition (optional):** A filter; only items meeting the condition are included.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "```python\n",
      "numbers = [1, 2, 3, 4, 5]\n",
      "\n",
      "# Create a new list containing the squares of even numbers\n",
      "squares = [x**2 for x in numbers if x % 2 == 0]  # [4, 16]\n",
      "\n",
      "print(squares)\n",
      "```\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "*   **Conciseness:**  More readable and compact than traditional `for` loops.\n",
      "*   **Readability:**  Can be easier to understand for simple list creation.\n",
      "*   **Efficiency:**  Often faster than equivalent loops (though the performance difference isn't always significant).\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First message\n",
    "print(\"Assistant:\")\n",
    "await prompt_streaming(assistant_session, \"What is a list comprehension?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:\n",
      "```python\n",
      "# Create a list of squares of even numbers from 0 to 9\n",
      "squares_of_evens = [x**2 for x in range(10) if x % 2 == 0]\n",
      "\n",
      "print(squares_of_evens)  # Output: [0, 4, 16, 36, 64]\n",
      "\n",
      "# Extract vowels from a string\n",
      "string = \"Hello World\"\n",
      "vowels = [char for char in string if char.lower() in \"aeiou\"]\n",
      "\n",
      "print(vowels) # Output: ['e', 'o', 'o']\n",
      "```"
     ]
    }
   ],
   "source": [
    "# Follow-up message (the assistant remembers the context)\n",
    "print(\"Assistant:\")\n",
    "await prompt_streaming(assistant_session, \"Can you show me an example?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Token Usage\n",
    "\n",
    "Monitor how many tokens you've used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current usage: 1144/9216 tokens\n",
      "\n",
      "This prompt would use approximately 13 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current usage: {assistant_session.input_usage}/{assistant_session.input_quota} tokens\")\n",
    "\n",
    "# Measure how many tokens a prompt would use\n",
    "usage = await assistant_session.measure_input_usage(\"What is machine learning?\")\n",
    "print(f\"\\nThis prompt would use approximately {usage} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "Use JSON schema to get structured responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n",
      "Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a JSON schema\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"required\": [\"sentiment\", \"score\"],\n",
    "    \"properties\": {\n",
    "        \"sentiment\": {\"type\": \"string\", \"enum\": [\"positive\", \"negative\", \"neutral\"]},\n",
    "        \"score\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Get structured response\n",
    "result = await lm.prompt(\n",
    "    \"Analyze this review: The product exceeded all my expectations! Absolutely amazing!\",\n",
    "    {\"responseConstraint\": schema},\n",
    ")\n",
    "\n",
    "# Parse the JSON response\n",
    "data = json.loads(result)\n",
    "print(f\"Sentiment: {data['sentiment']}\")\n",
    "print(f\"Score: {data['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Cloning\n",
    "\n",
    "Clone a session to create different conversation branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Branch 1 ===\n",
      "Once upon a time, there was a dragon named Zephyr. Now, dragons weren't typically known for being friendly and helpful. They roared, they hoarded gold, they breathed fire. And Zephyr… Zephyr preferred dandelion fluff.\n",
      "\n",
      "He wasn’t your typical, menacing dragon, oh no. His scales were the color of a sunset – soft oranges melting into gentle pinks and purples. Instead of a fearsome roar, he emitted a sort of contented sigh, like a warm breeze rustling through leaves. And while he did have a hoard, it wasn't gold or jewels. It was a meticulously curated collection of wildflowers, each petal preserved in delicate, shimmering amber.\n",
      "\n",
      "He lived in a secluded valley nestled between towering, snow-capped peaks, a valley renowned not for its riches, but for its breathtaking meadows overflowing with blooms. Zephyr spent his days tending to these meadows, coaxing shy blossoms to open, whispering encouragement to struggling vines, and ensuring that the valley always smelled of honeysuckle and sunshine.\n",
      "\n",
      "The villagers in the nearby town of Oakhaven, initially terrified, slowly began to realize Zephyr wasn't the monstrous beast the legends claimed. He was actually incredibly helpful! When a landslide threatened their village, Zephyr used his powerful wings to gently divert the rocks, saving homes and lives. When a terrible blight struck their crops, he exhaled a gentle, revitalizing mist that restored the fields to health. And when winter brought a harsh freeze, he curled around the village, radiating warmth and shielding them from the biting winds.\n",
      "\n",
      "He’d also help with smaller tasks. He'd use his long tail to pull stranded carts out of snowdrifts, his fiery breath – carefully controlled, of course – to melt ice from pathways, and his keen eyesight to spot lost children wandering in the mountains. He was always willing to lend a claw, or a wing, or a gentle nudge.\n",
      "\n",
      "The villagers, in turn, showered him with affection. They brought him baskets of the sweetest fruits, crafted him comfy nests of soft moss, and told him stories of their lives – stories that he listened to with patient, golden eyes. He became a beloved protector and friend, a symbol of kindness and generosity. \n",
      "\n",
      "But Zephyr wasn't without a secret. He yearned to experience the world beyond his valley, to see the shimmering coastline, to hear the crashing waves, to understand the stories whispered on the wind. The problem was, dragons, even the most friendly and helpful ones, weren't exactly known for their adventurous spirit. And Zephyr wasn't sure where to even begin. \n",
      "\n",
      "He’d spend his evenings gazing at the stars, wondering if there was more to life than tending meadows and helping villagers. And so began Zephyr's quiet quest – a quest not for gold or power, but for a little bit of adventure, and perhaps, a little bit more to give.\n",
      "\n",
      "\n",
      "\n",
      "=== End of 1 ===\n",
      "=== Branch 2 ===\n",
      "Once upon a time, there was a dragon named Ignis. Now, dragons weren't typically known for being gentle creatures. They roared, they hoarded gold, they breathed fire. And Ignis… Ignis embodied the very essence of a terrifying beast.\n",
      "\n",
      "His scales were obsidian, shimmering like polished night. Razor-sharp horns curved back from his skull, and smoke constantly curled from his nostrils. His eyes, twin pools of molten gold, burned with an ancient, untamed power. Instead of a contented sigh, he unleashed a deafening roar that rattled the very mountains. And yes, he hoarded gold – mountains of it, glittering and gleaming in his cavernous lair. \n",
      "\n",
      "He ruled the jagged peaks of Dragon's Tooth Mountain, a formidable presence that instilled fear in the hearts of even the bravest knights. Villages scattered across the valleys trembled at the thought of his fiery breath, and tales of his ruthless strength were whispered in hushed tones around crackling fires. \n",
      "\n",
      "Ignis didn't crave gold for its own sake. He collected it as a symbol of his dominion, a testament to his unwavering power. Each coin represented a defeated foe, a subjugated kingdom, a reminder of the fear he inspired. He relished the feeling of control, the weight of responsibility, the sheer awe (and terror) he commanded.\n",
      "\n",
      "His days were spent patrolling his territory, ensuring no mortal dared trespass on his domain. He’d survey the valleys below, a watchful guardian, always alert for any sign of rebellion or defiance. He was a creature of instinct, driven by a primal need for strength and respect. \n",
      "\n",
      "But beneath the fearsome exterior, a flicker of something else resided. A deep loneliness. The constant fear and reverence he inspired kept others at arm's length. He was surrounded by gold, but utterly alone. He’d sometimes stare into the reflection of his hoard, wondering if there was anything more to life than power and dominance.\n",
      "\n",
      "Ignis wasn't inherently evil, merely… formidable. And his fierce nature, honed over centuries of unchallenged rule, had built a formidable wall around his heart, making it almost impossible for anyone to penetrate.\n",
      "\n",
      "\n",
      "\n",
      "=== End of 2 ===\n"
     ]
    }
   ],
   "source": [
    "# Start a story\n",
    "story_session = await LanguageModel.create(\n",
    "    {\"initialPrompts\": [{\"role\": \"system\", \"content\": \"You are a creative storyteller.\"}]}\n",
    ")\n",
    "\n",
    "await story_session.prompt(\"Once upon a time, there was a dragon.\")\n",
    "\n",
    "# Create two different story branches\n",
    "branch1 = await story_session.clone()\n",
    "branch2 = await story_session.clone()\n",
    "\n",
    "print(\"=== Branch 1 ===\")\n",
    "await prompt_streaming(branch1, \"The dragon was friendly and helpful.\")\n",
    "print(\"=== End of 1 ===\")\n",
    "\n",
    "print(\"=== Branch 2 ===\")\n",
    "await prompt_streaming(branch2, \"The dragon was fierce and terrifying.\")\n",
    "print(\"=== End of 2 ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Destroy sessions when you're done to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All sessions destroyed\n"
     ]
    }
   ],
   "source": [
    "await lm.destroy()\n",
    "await assistant_session.destroy()\n",
    "await story_session.destroy()\n",
    "await branch1.destroy()\n",
    "await branch2.destroy()\n",
    "\n",
    "print(\"✅ All sessions destroyed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
